Dear MongoDB Support Team,

I hope this message finds you well. I am reaching out to seek clarification and guidance on a couple of aspects related to MongoDB Atlas and its operations, which are crucial for optimizing our database management and search functionalities.

Facet Queries on Sharded Collections: We are considering leveraging Atlas Search's facet queries over sharded collections to enhance our application's search capabilities. However, we noted in the documentation Atlas Search Facet Over Sharded Collections a requirement that the cluster must run MongoDB v6.0 or higher for such queries. Additionally, it mentions that on sharded Atlas clusters running MongoDB v7.2.0, $searchMeta might return an error for facet queries. Could you provide further insights into this limitation and any best practices or workarounds you recommend? Our goal is to implement efficient and reliable facet search functionality in our sharded environment.

Use of renameCollection() for Nightly Batch Loads: We are exploring the use of renameCollection() for swapping tables as part of our nightly batch load process. Our primary concern is the atomicity of this operation and whether there might be an intermediate state during the rename process where the collection is not accessible, potentially affecting our application's availability. Could you confirm if the renameCollection() operation is atomic and if there are any accessibility concerns we should be aware of? Additionally, any advice on best practices for using renameCollection() in such a scenario would be greatly appreciated.




The process we envision is as follows:

a. Populate a new collection (new_data_collection) with the latest data during the night.

b. Once the new collection is fully prepared and indexed, use renameCollection() to atomically replace the existing collection (current_data_collection) with new_data_collection. The intended command sequence is to rename current_data_collection to backup_data_collection (for rollback capabilities) and subsequently rename new_data_collection to current_data_collection.

c. This swap allows our application to immediately start using the updated data with minimal downtime or service interruption.

Our primary concerns with this approach are:

Atomicity: We seek confirmation on whether the renameCollection() operation is atomic from the perspective of client applications. Specifically, is there any moment during the rename process where current_data_collection would be unavailable to client queries?

Accessibility: Related to atomicity, we are interested in understanding if there is an intermediate state during the swapping process where neither the old nor the new collection is accessible, potentially leading to query errors or downtime.

Best Practices: Any recommendations or best practices for implementing this process, especially considerations for minimizing impact on application availability and ensuring a smooth transition between collections.







Dear MongoDB Support Team,

I hope this message finds you well. I am reaching out to inquire about the capabilities of MongoDB Atlas Search, specifically regarding the management and analysis of index objects within Atlas Search indexes.

My application involves a significant amount of data, and I am concerned about staying within the known limitations for index objects in Atlas Search indexes. To give you a clear picture, here's an overview of the data structure and volume I am working with:

Households: 10 million
Stores: 2
Offers: 500 for each household
Categories, Events, OfferTypes: 30 each
Total Documents: Approximately 5 billion
I understand from the documentation that Atlas Search does not support indexing more than two billion index objects, with the definition of an index object extending beyond top-level documents to include embedded documents and other indexable fields. Given my application's scale, I am concerned about inadvertently exceeding this limit and facing issues with index failure or degraded performance.

Could you please provide guidance or tools within MongoDB Atlas that can help me:

Determine the current count of index objects for my Atlas Search indexes?
Monitor the count of index objects over time to prevent exceeding the limit?
Strategize on best practices for structuring my data and indexes to stay within safe operational limits?
Your insights and suggestions will be incredibly valuable as I plan the scalability and performance optimization of my application. I am keen to ensure that my usage of Atlas Search aligns with best practices and the technical limitations of the platform.

Thank you very much for your time and assistance. I look forward to your response.
